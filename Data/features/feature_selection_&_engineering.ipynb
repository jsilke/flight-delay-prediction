{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Feature Selection and Engineering**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fl_date</th>\n",
       "      <th>mkt_unique_carrier</th>\n",
       "      <th>branded_code_share</th>\n",
       "      <th>mkt_carrier</th>\n",
       "      <th>mkt_carrier_fl_num</th>\n",
       "      <th>op_unique_carrier</th>\n",
       "      <th>tail_num</th>\n",
       "      <th>op_carrier_fl_num</th>\n",
       "      <th>origin_airport_id</th>\n",
       "      <th>origin</th>\n",
       "      <th>...</th>\n",
       "      <th>dest_airport_id</th>\n",
       "      <th>dest</th>\n",
       "      <th>dest_city_name</th>\n",
       "      <th>crs_dep_time</th>\n",
       "      <th>crs_arr_time</th>\n",
       "      <th>dup</th>\n",
       "      <th>crs_elapsed_time</th>\n",
       "      <th>flights</th>\n",
       "      <th>distance</th>\n",
       "      <th>arr_delay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-05-19</td>\n",
       "      <td>UA</td>\n",
       "      <td>UA_CODESHARE</td>\n",
       "      <td>UA</td>\n",
       "      <td>4264</td>\n",
       "      <td>EV</td>\n",
       "      <td>N48901</td>\n",
       "      <td>4264</td>\n",
       "      <td>12266</td>\n",
       "      <td>IAH</td>\n",
       "      <td>...</td>\n",
       "      <td>12915</td>\n",
       "      <td>LCH</td>\n",
       "      <td>Lake Charles, LA</td>\n",
       "      <td>1020</td>\n",
       "      <td>1112</td>\n",
       "      <td>N</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1</td>\n",
       "      <td>127</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-05-19</td>\n",
       "      <td>UA</td>\n",
       "      <td>UA_CODESHARE</td>\n",
       "      <td>UA</td>\n",
       "      <td>4266</td>\n",
       "      <td>EV</td>\n",
       "      <td>N12540</td>\n",
       "      <td>4266</td>\n",
       "      <td>13244</td>\n",
       "      <td>MEM</td>\n",
       "      <td>...</td>\n",
       "      <td>12266</td>\n",
       "      <td>IAH</td>\n",
       "      <td>Houston, TX</td>\n",
       "      <td>1148</td>\n",
       "      <td>1340</td>\n",
       "      <td>N</td>\n",
       "      <td>112.0</td>\n",
       "      <td>1</td>\n",
       "      <td>468</td>\n",
       "      <td>-14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-05-19</td>\n",
       "      <td>UA</td>\n",
       "      <td>UA_CODESHARE</td>\n",
       "      <td>UA</td>\n",
       "      <td>4272</td>\n",
       "      <td>EV</td>\n",
       "      <td>N11164</td>\n",
       "      <td>4272</td>\n",
       "      <td>12266</td>\n",
       "      <td>IAH</td>\n",
       "      <td>...</td>\n",
       "      <td>11042</td>\n",
       "      <td>CLE</td>\n",
       "      <td>Cleveland, OH</td>\n",
       "      <td>1155</td>\n",
       "      <td>1551</td>\n",
       "      <td>N</td>\n",
       "      <td>176.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1091</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-05-19</td>\n",
       "      <td>UA</td>\n",
       "      <td>UA_CODESHARE</td>\n",
       "      <td>UA</td>\n",
       "      <td>4281</td>\n",
       "      <td>EV</td>\n",
       "      <td>N13995</td>\n",
       "      <td>4281</td>\n",
       "      <td>11042</td>\n",
       "      <td>CLE</td>\n",
       "      <td>...</td>\n",
       "      <td>11278</td>\n",
       "      <td>DCA</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>839</td>\n",
       "      <td>959</td>\n",
       "      <td>N</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1</td>\n",
       "      <td>310</td>\n",
       "      <td>-20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-05-19</td>\n",
       "      <td>UA</td>\n",
       "      <td>UA_CODESHARE</td>\n",
       "      <td>UA</td>\n",
       "      <td>4286</td>\n",
       "      <td>EV</td>\n",
       "      <td>N13903</td>\n",
       "      <td>4286</td>\n",
       "      <td>13061</td>\n",
       "      <td>LRD</td>\n",
       "      <td>...</td>\n",
       "      <td>12266</td>\n",
       "      <td>IAH</td>\n",
       "      <td>Houston, TX</td>\n",
       "      <td>710</td>\n",
       "      <td>826</td>\n",
       "      <td>N</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1</td>\n",
       "      <td>301</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fl_date mkt_unique_carrier branded_code_share mkt_carrier  \\\n",
       "0  2019-05-19                 UA       UA_CODESHARE          UA   \n",
       "1  2019-05-19                 UA       UA_CODESHARE          UA   \n",
       "2  2019-05-19                 UA       UA_CODESHARE          UA   \n",
       "3  2019-05-19                 UA       UA_CODESHARE          UA   \n",
       "4  2019-05-19                 UA       UA_CODESHARE          UA   \n",
       "\n",
       "   mkt_carrier_fl_num op_unique_carrier tail_num  op_carrier_fl_num  \\\n",
       "0                4264                EV   N48901               4264   \n",
       "1                4266                EV   N12540               4266   \n",
       "2                4272                EV   N11164               4272   \n",
       "3                4281                EV   N13995               4281   \n",
       "4                4286                EV   N13903               4286   \n",
       "\n",
       "   origin_airport_id origin  ... dest_airport_id  dest    dest_city_name  \\\n",
       "0              12266    IAH  ...           12915   LCH  Lake Charles, LA   \n",
       "1              13244    MEM  ...           12266   IAH       Houston, TX   \n",
       "2              12266    IAH  ...           11042   CLE     Cleveland, OH   \n",
       "3              11042    CLE  ...           11278   DCA    Washington, DC   \n",
       "4              13061    LRD  ...           12266   IAH       Houston, TX   \n",
       "\n",
       "  crs_dep_time  crs_arr_time  dup crs_elapsed_time  flights  distance  \\\n",
       "0         1020          1112    N             52.0        1       127   \n",
       "1         1148          1340    N            112.0        1       468   \n",
       "2         1155          1551    N            176.0        1      1091   \n",
       "3          839           959    N             80.0        1       310   \n",
       "4          710           826    N             76.0        1       301   \n",
       "\n",
       "   arr_delay  \n",
       "0       -2.0  \n",
       "1      -14.0  \n",
       "2        4.0  \n",
       "3      -20.0  \n",
       "4       -1.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights_test = pd.read_csv('../files/flights_test_no_missing.csv')\n",
    "feature_space = list(flights_test.columns)\n",
    "feature_space.append('arr_delay') # Add the target.\n",
    "\n",
    "flights = pd.read_csv('../files/flights_no_missing.csv')\n",
    "flights_subspace = flights[feature_space].copy()\n",
    "flights_subspace.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimate of prediction set size relative to train/test/validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.165286444822605"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights_test.shape[0] / flights.shape[0] * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our aim for this section is to use the feature space available to the **flights_test** dataframe containing the target range of dates for our prediction submission (January 1 - 7, 2020, inclusive) to select and engineer a range of fetures that best capture the common causes for flight delays. The prediction submission dates are to be treated as if they are in the future for the purpose of generating an appropriate prediction; as such, no historic data for these dates should be considered. Features will be engineered and selected on the basis of how they best captured the different delay classes available to us during the exploration phase of the study."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **flights**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features considered here should be engineered and selected only from the subset present in both **flights** and **flights_test**. Since we know the **flights_test** feature space is a subset of the **flights** feature space, we will simply use the columns in flights_test to filter the feature space of flights to prepare our data for transformation and modelling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* all ids can be discarded initially (except for the `origin` and `dest` ids), but they may also be ranked by delay if that turns out to be interesting/feasible\n",
    "* `flights` column is always 1; completely uninformative\n",
    "* dest and origin city names information is already captured by origin and destination, but the `state` could be useful in a later iteration (e.g. binarized to something like `busy_state` for high traffic origins/destinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = [\n",
    "    'mkt_unique_carrier',\n",
    "    'mkt_carrier',\n",
    "    'mkt_carrier_fl_num',\n",
    "    'op_unique_carrier',\n",
    "    'tail_num',\n",
    "    'op_carrier_fl_num',\n",
    "    'origin',\n",
    "    'dest',\n",
    "    'dest_city_name',\n",
    "    'origin_city_name',\n",
    "    'flights']\n",
    "\n",
    "submission_columns = ['fl_date', 'mkt_carrier', 'mkt_carrier_fl_num', 'origin', 'dest']\n",
    "\n",
    "flights_test_drop = set(to_drop) - set(submission_columns)\n",
    "\n",
    "flights_subspace = flights_subspace.drop(columns=to_drop)\n",
    "flights_test = flights_test.drop(columns=flights_test_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_subspace['day_of_week'] = pd.to_datetime(flights_subspace['fl_date']).dt.dayofweek\n",
    "flights_subspace['month_of_year'] = pd.to_datetime(flights_subspace['fl_date']).dt.month\n",
    "\n",
    "flights_test['day_of_week'] = pd.to_datetime(flights_test['fl_date']).dt.dayofweek\n",
    "flights_test['month_of_year'] = pd.to_datetime(flights_test['fl_date']).dt.month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us check the relationship with arrival delay for these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "day_of_week\n",
       "0    6.696040\n",
       "1    4.567373\n",
       "2    4.458588\n",
       "3    7.273884\n",
       "4    6.993864\n",
       "5    2.512690\n",
       "6    5.173920\n",
       "Name: arr_delay, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights_subspace.groupby('day_of_week')['arr_delay'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "month_of_year\n",
       "1      3.923047\n",
       "2      6.693371\n",
       "3      2.902349\n",
       "4      4.071800\n",
       "5      6.448396\n",
       "6     10.562826\n",
       "7      8.871938\n",
       "8      8.883695\n",
       "9      1.694430\n",
       "10     2.810083\n",
       "11     3.071748\n",
       "12     5.087656\n",
       "Name: arr_delay, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights_subspace.groupby('month_of_year')['arr_delay'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above, although we can separate into discrete ranks by mean, some classes are much closer on average than others which is an inherent drawback of this method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_subspace = flights_subspace.drop('fl_date', axis=1)\n",
    "\n",
    "flights_subspace.to_csv('../files/flights_engi.csv', index=False)\n",
    "flights_test.to_csv('../files/flights_test_engi.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8d6676aaa1277e38a8b007c79f4c02c0460f54b902bd054fa5584050907dc207"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('LHL': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
